% Als Referenz und Grundlage fuer die Definitionen nutze ich das Lehrbuch Combinatorial Optimization:Theory and 
%Algorithms von Bernhard Korte u Jens Vygen - definiere die wichtigsten Sachen aber erstmal auch selbst
\subsection{Graph Theory Basics}
Since there are many definitions in graph theory which may differ slightly, we want to introduce now the basic notation 
and definitions that we use throughout this thesis. The definitions in this chapter are mainly taken from the textbook 
about combinatorial optimization by Korte and Vygen \cite{KorteVygenCombOpt2007}.

\begin{definition}

An \textit{undirected graph} is a triple (V, E, $\Psi$), where $V$ and $E$ are finite sets and
$\Psi: E\to \{X \subseteq V: |X| = 2\}$. \\
A \textit{directed graph or digraph} is a triple $(V, E, \Psi)$,
where $V$ and $E$ are finite sets and $\Psi : E \to \{(v, w) \in V \times V : v \neq w\}$. 
In application to the gas problem we might call the graph modelling the gas infrastructure a \textit{network}. 
\end{definition}
 
The elements of $V$ are called \textit{vertices}, the elements of $E$ are called the \textit{edges}. $\Psi$ is the 
incidence function giving the relation between elements of $V$ and elements of $E$. 

In this thesis by a graph we normally mean the directed graph. If we talk about undirected graphs it will be stated 
explicitly. Edges of directed graphs will also be called \textit{arcs} to make clear that they are directed.\\

Two edges $e, e'$ with $\Psi(e) = \Psi ( e')$ are called parallel. Graphs without parallel
edges are called simple. For simple graphs we usually identify an edge $e$ with its
image $\psi(e)$ and write $G = (V(G), E(G))$ or $G=(V,E)$, where $E(G) \subseteq \{X \subseteq V(G) : |X| = 2\}$
or $E(G) \subseteq V(G) \times V(G)$. %We often use this simpler notation even in the presence
%of parallel edges, then the ``set'' $E (G)$ may contain several "identical'' elements. 
In this thesis all graphs are considered simple so we use this notation. 
%rausnehmen weil gar keine parallelen Kanten gebraucht werden
 
\begin{definition}
$|E(G)|=m$ denotes the number of edges and $|V(G)|=n$ denotes the number of vertices of a graph.
\end{definition}
\begin{definition}

We say that an edge $e = \{v, w\}$ or $e = (v, w)$ joins $v$ and $w$. In this case, $v$ and $w$ are \textit{adjacent}. 
$v$ is a \textit{neighbour} of $w$ (and vice versa). $v$ and $w$ are the \textit{endpoints} of $e$. If $v$ is an 
endpoint of an edge $e$, we say that $v$ is \textit{incident} with $e$. 
In the directed case we say that $e=( v, w)$ leaves $v$ and enters $w$,
$v$ is the \textit{tail} and $w$ is the \textit{head} of the arc $e$. 
Two edges which share at least one endpoint are 
called adjacent. 
\end{definition}

\begin{definition}
For a digraph $G$ the \textit{underlying undirected graph} is the undirected graph $G'$ on the same 
vertex set which contains an edge $\{v, w\}$
for each edge $(v, w)$ of $G$. We also say that $G$ is an orientation of $G'$.
\end{definition}
\begin{definition}
A \textit{subgraph} of a graph $G = (V(G), E(G))$ is a graph $H = (V(H), E(H))$
with $V(H) \subset V(G)$ and $E(H) \subset E(G)$. We also say that $G$ contains $H$. $H$ is an
induced subgraph of $G$ if it is a subgraph of $G$ and $E (H) = \{ \{x, y\} \textrm{ resp. } (x, y) \in
E(G) : x, y \in V(H)\}$. 
Here $H$ is the subgraph of $G$ induced by $V(H)$. 
\end{definition}
% A subgraph $H$ of $G$ is called spanning if $V(H) = V(G)$.

% If $v \in V(G)$, we write $G- v$ for the subgraph of $G$ induced by $V(G) \setminus {v}$.
\begin{definition}
For $e \in E(G)$, we define $G- e := (V(G), E(G) \setminus \{e\})$. Furthermore, the addition
of a new edge $e$ is abbreviated by $G + e := (V(G), E(G) \cup {e})$. 
% If $G$ and $H$ are two graphs, we denote by $G + H$ the graph with $V(G +H)= V(G) \cup V(H)$
% and $E(G +H)$ being the disjoint union of $E(G)$ and $E(H)$ (parallel edges may arise).
\end{definition}

% For a graph $G$ and $X, Y\subseteq V(G)$ we define $E(X, Y) := \{\{x, y\} \in E(G) : x \in
% X \setminus Y, y \in Y \setminus X\}$ resp. $E^+(X, Y) := \{(x, y) \in E(G) : x \in X\setminus Y, y \in Y \setminus 
% X\}$.
% For undirected graphs $G$ and $X \subseteq V(G)$ we define $\delta(X) := E(X, V(G) \setminus X)$. The
% set of neighbours of $X$ is defined by $ \Gamma(X) := \{v \in V(G) \setminus X : E(X, \{v\})  \neq \emptyset\}$.
% For digraphs $G$ and $X \subseteq V(G)$ we define $\delta^+(X) := E^+(x, V(G) \setminus X)$, $\delta^-(x) :=
% \delta^+(V(G) \setminus X)$ and $\delta(X) := \delta^+(x) \cup \delta^-(x)$. We use subscripts (e.g. $\delta_G(X)$) to
% specify the graph $G$ if necessary.
% 
% For singletons, i.e. one-element vertex sets $\{v\} (v \in V(G))$ we write $\delta(v) :=
% \delta(\{v\})$, $\Gamma(v) := \Gamma(\{v\}), \delta^+(v) := \delta^+(\{v\})$ and $\delta^-(v) := \delta^-(\{v\})$. 
% The 
% degree of a vertex $v$ is $|\delta(v)|$, the number of edges incident to $v$. In the directed case, the
% in-degree is $|\delta^-(v)|$, the out-degree is $|\delta^+(v)|$, and the degree is $|\delta^+(v)|+ |\delta^-(v)|$.
% A vertex $v$ with zero degree is called isolated. A graph where all vertices have
% degree $k$ is called $k$-regular.
\begin{definition}
For undirected graphs $G$ and a set of vertices $X \subseteq V(G)$ we define the cut induced by $X$
$$\delta(X) := \{\{x, y\} \in E(G) : x \in X , y \in V(G) \setminus X\}$$
%The set of neighbours of $X$ is defined by $ \Gamma(X) := \{v \in V(G) \setminus X : E(X, \{v\})  \neq \emptyset\}$.
For digraphs $G$ and $X \subseteq V(G)$ we define 
$$\delta^+(X) := \{(x, y) \in E(G) : x \in X , y \in V(G) \setminus X\}$$ and
$$\delta^-(X) := \{(y, x) \in E(G) : x \in X , y \in V(G) \setminus X\}$$
% and $\delta(X) := \delta^+(x) \cup \delta^-(x)$. 
 
For one-element vertex sets $\{v\}$ (with $v \in V(G))$ we write $\delta(v) :=\delta(\{v\})$ for the set of incident 
edges of $v$, and in the directed case 
$ \delta^+(v) := \delta^+(\{v\})$ for the outgoing arcs and $\delta^-(v) := \delta^-(\{v\})$ for the set of ingoing 
arcs of $v$
\end{definition}
We use subscripts (e.g. $\delta_G(X)$) to specify the graph $G$ if necessary.
\begin{definition}
The \textit{degree} of a vertex $v$ is $|\delta(v)|$, the number of edges incident to $v$. In the directed 
case, the in-degree is $|\delta^-(v)|$, the out-degree is $|\delta^+(v)|$, and the degree is 
$|\delta^+(v)|+ |\delta^-(v)|$.
\end{definition}
A vertex $v$ with zero degree is called isolated. A graph where all vertices have degree $k$ is called $k$-regular.

\begin{definition}
An \textit{edge progression} $W$ in $G$ is a sequence $v_1, e_1, v_2, \dots , v_k, e_k, v_{k+1}$ such that $k 
\ge 0$, and $e_i = (v_i, v_{i+ 1}) \in E(G)$ resp. $e_i = \{v_i, v_{i+1}\}\in E(G)$ for $i = 1, \dots , k$. If in
addition $e_i \ne e_j \,\forall\, 1 \le i < j \le k$, $W$ is called a \textit{walk} in $G$. $W$ is \textit{closed} if
$v_1 = v_{k+1}$. 

A \textit{path} is a graph $P = (\{v_1, ... , v_{k+1}\}, \{e_1, ... , e_k\})$ such that $v_i \ne v_j$ for
$1 \le i < j \le k + 1$ and the sequence $v_1 , e_1 , v_2, \dots , v_k, e_k, v_{k+1}$ is a walk. $P$ is
called a path from $v_1$ to $v_{k+1}$ or a $v_1 - v_{k+1}$-path. $v_1$ and $v_{k+1}$ are the endpoints
of $P$.
% By $P_{[x,y]}$ with $x, y \in V(P)$ we mean the (unique) subgraph of $P$ which is an $x-y$-path. 
 
\end{definition}
Evidently, there is an edge progression from a vertex $v$ to another vertex $w$ if and only if there is a $v-w$-path.
\begin{definition}

A \textit{cycle} is a graph $(\{v_1, \dots , v_k\}, \{e_1, \dots, e_k\})$ such that the sequence $v_1, e_1, v_2, 
\dots , v_k,e_k,v_1$ is a (closed) walk and $v_i \ne v_j$ for $1 \le i < j\le k$.
 
\end{definition}
An easy induction argument shows that the edge set of a closed walk can be partitioned into edge sets of cycles.

%eingefuegt: definition kreisbasis
\begin{definition}
 For cycles $C_1$, $C_2$ in a graph we define a cycle addition operation or sum of cycles as symmetric difference 
 $C_1+C_2=(C_1\cup C_2)\setminus (C_1\cap C_2)$. 
 
 With this operation we can define a \textit{cycle base} as a minimal 
set of cycles $\mathbb{B}=\{C_1,C_2,\dots, C_l\}$ such that we can represent every possible cycle in the graph as sum 
$\sum_{i=1}^k C_i\,|\C_i\in\mathbb{B}$ of cycles in the cycle base.
\end{definition}

 
\begin{definition}
The length of a path or cycle is the number of its edges. If it is a subgraph of $G$, we speak of a path or cycle in 
$G$. 
\end{definition}

\begin{definition}
A spanning path (i.e. a path containing all vertices) in $G$ is called a \textit{Hamiltonian path} while a spanning 
cycle in $G$ is called a \textit{Hamiltonian cycle}. A graph containing a Hamiltonian cycle is a \textit{Hamiltonian 
graph}.
\end{definition}

\begin{definition}
 A \textit{ connected component } of a graph $G$ is a subgraph $G'\subseteq G$ such that there is a path in $G'$ from 
 every node $v\in G'$ to every other node $u\in G'$. We call a graph $G$ that forms a connected component on its own 
 \textit{connected}. 
\end{definition}


\begin{definition}
For two vertices $v$ and $w$ we write $dist(v, w)$ or $dist_G (v, w)$ for the length of
a shortest $v-w$-path (the \textit{distance} from $v$ to $w$) in $G$. If there is no $v-w$-path at all,
i.e. $w$ is not reachable from $v$, we set $dist(v, w) := \inf$. In the undirected case,
$dist(v, w) = dist(w, v)$ for all $v, w \in V(G)$.
\end{definition}

\begin{definition}

We shall often have a cost function $c : E(G) \to \R$. Then for $F \subseteq E(G)$ we
write $c(F) := \sum_{e\in F} c(e)$ (and $c(\emptyset) = 0$). This extends $c$ to a modular function
$c : 2^{E(G)}\to \R$. Moreover, $dist_{(G,c)}(v, w)$ denotes the minimum $c(E(P))$ over all
$v-w$-paths $P$ in $G$.
 
\end{definition}

\subsection{Combinatorial Optimization}
%TODO
Optimization of mathematical problems including to make certain discrete decisions is an important field of application 
for modern mathematics. The acyclic flow problem we describe in this thesis is a typical example of a combinatorial, 
graph theoretical optimization problem. Here we define such problems in general as well as the basics of integer 
programming which is a standard approach to solve such problems. 

The definitions are taken from the scriptum of the course ADM I by Martin Gr\"otschel held in 2012/2013, see 
\cite{groetschelSkript}. %TODO referenz

\begin{definition}
 Given a finite set $\mathcal{I}$ and a function $f:\mathcal{I}\to\R$. The problem of finding the element 
$i\in\mathcal{I}$ such that $f(i)$ is maximum or minimum is a general \textit{combinatorial optimization problem}.
\end{definition}
Of course it is hard to solve such a problem without having any structure on it. But the problems we have to deal with 
normally have  a good structure on them: The set $\mathcal{I}$ is defined implicitly by some conditions on its elements 
and the function $f$ is defined by formulas.

\begin{definition}
 Given some finite set $E$ , a set $\mathcal{I}\subset \mathcal{P}(E)$ of feasible solutions and a function 
 $c:E\to \R$. Define for a set $S \in \mathcal{P}(E)$ the total costs $c':\mathcal{P}(E)\to \R$, 
 $c'(S)=\sum_{s\in S}c(s)$. 
 
 The problem of finding an element $i_m\in\mathcal{I}$ with $c'(i_m)\ge c'(i)\forall 
 i\in\mathcal{I} $ (or $c'(i_m)\le c'(i)\forall i\in\mathcal{I} $) we call a \textit{combinatorial maximization 
(minimization)  problem} with linear objective function.
\end{definition}

Often we can model such combinatorial optimization problems as linear, mixed-integer, quadratic or constraint program 
depending on the definition of the feasible set $\mathcal{I}$. 

As we will make use of such programs we want to define the basics here. We use the framework SCIP ("Solving Constraint 
Integer Programs") for solving our problem. For details of the solver setup we refer to the PhD Thesis of Tobias 
Achterberg \cite{Achterberg2007} where he describes the main design of his Constraint Integer Programming solver SCIP. 
The following definitions also follow the work of Achterberg \cite{Achterberg2007}.

\begin{definition}
 A \textit{constraint program} is a triple $(\mathcal{C},\mathcal{D},f)$ and consists of solving
 $$f^*=\min\{f(x)|x\in \mathcal{D}, \mathcal{C}(x)\}$$ 
 with $\mathcal{D}=\mathcal{D}_1\times \dots\times \mathcal{D}_n$ the domain set, $f:\mathcal{D}\to\R$ the objective 
function and $\mathcal{C}=\{\mathcal{C}_1\dots \mathcal{C}_m\}$ the constraint set.
\end{definition}

As a special case of constraint programs that can be handled by computers and can be used to model many different 
combinatorial optimization problems we have mixed integer programs (or shortly referred to as MIP). Here the 
constraints and the objective function can be given as linear inequalities and in addition the domains of some 
variables can be restricted to integer values. Often variable domains are even more specifically restricted to 
$\{0,1\}$. The regarding variables are called binary (decision) variables.

\begin{definition}
 A \textit{mixed integer program} or \textit{MIP} is a constraint program with the following representation:\\
 Given a matrix $A\in\R^{m\times n}$, vectors $c\in\R^n$ and $b\in \R^m$ and a set $\mathcal{I}\subseteq \{1\dots n\}$ 
 we have to solve
 $$c^*=\min\{c^T x|Ax\le b, x\in\R^n, x_j\in\mathbb{Z}\textrm{ for all }j\in\mathcal{I} \}$$
 We call all the vectors x in the set
 $$X_\textit{MIP}=\{x\in\R^n|A x\le b, x\in\R^n, x_j\in\mathbb{Z}\textrm{ for all }j\in\mathcal{I} \}$$
 i.e. vectors fulfilling the constraints of the problem, the \textit{feasible solutions} of the MIP. A vector $x'\in 
 X_\textit{MIP}$ with $c^*=c^Tx'$ is called an \textit{optimal solution} of the MIP.
\end{definition}

There are important special cases of mixed integer programs: The set $\mathcal{I}$ of integer variables could be empty 
so we really just optimize over a polyhedron. This kind of MIP with $\mathcal{I}=\emptyset$ is called a \textit{linear 
program} or \textit{LP}. 

It can also happen that every variable is integer, i.e. $\mathcal{I}=\{1,\dots, n\}$. We call this MIP an 
\textit{integer program} or \textit{IP} in this case.

Solving linear programs can be done in polynomial time. Algorithms to achieve this were described by 
Khachiyan\cite{KHACHIYAN198053} and Karmarkar \cite{Karmarkar:1984:NPA:800057.808695}. Integer programs and by this 
also their generalization mixed integer programs can be (and mainly are) used for modeling $\mathcal{NP}$ hard 
problems. So unless $\mathcal{P}=\mathcal{NP}$ there is no polynomial algorithm to solve them.

Thus the LP relaxation of a MIP is a very important problem.
\begin{definition}
 The \textit{LP-relaxation} of a mixed integer program 
 $$\min\{c^T x|Ax\le b, x\in\R^n, x_j\in\mathbb{Z}\textrm{ for all }j\in\mathcal{I} \}$$
 is the MIP without any integrality constraints:
 $$\min\{c^T x|Ax\le b, x\in\R^n \}$$
\end{definition}

It can be solved efficiently since it is a linear program. The solution of the LP relaxation of a problem gives a
bound on the solution of the mixed integer problem. It is used to get a starting 
point for a branching process or for cutting planes, heuristics etc. that might yield an optimal or nearly optimal 
solution. 

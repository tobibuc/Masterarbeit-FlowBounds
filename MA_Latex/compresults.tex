% The models we described have also been implemented and tested on networks of different size.
\label{chapter:compresults}
In this section we will discuss the practical implementations and present results of the computation. For relevant 
real-world problem sizes the exact models are too slow, even with separation of the acyclicity constraints. For this 
reason we also describe how to relax the problem in order to get useable (though in general not optimal) results for the 
flow bounds. 
We compare the bounds found by different approaches and with different settings (different networks and nominations) 
to see which approach is suited best to actually compute acyclic flow bounds in a network. We also describe in short 
how the standard bounds we used to compare the results to are computed. 

At last we compare the impact of bounds and the number of fixed variables fed into the solver on the model sizes of the 
discretization. \\

\section{Implemented Algorithms}

We described the theoretical backgrounds of different algorithms to obtain flow bounds for our problem. The 
computational results of different implementations of them may vary widely, and the performance is influenced by lots 
of details regarding the machines, programming languages, data structures or just code quality. Nevertheless we want 
to give an overview what worked well in the implementation and what did not.\\

\subsection{MIP with Node Potentials and Binary Direction Variables}
The mixed integer programming model described in \ref{model:nodePotential} was implemented with Lamatto \cite{lamatto}, 
using Gurobi \cite{gurobi} as solver. In this model there are two layers of indicator constraints. This seems to be a 
heavy problem of the model, whose performance shall be discussed later. The following model was implemented:
\begin{align*}
  &\min \sum_{a\in A} w_a\cdot q_a & \\
 s.t. & \sum_{a\in \delta^+(v)}q_a - \sum_{a\in\delta^- (v)}q_a &=& d_v, &\forall v\in V \\
 & q_a &\le& c_u(a),& \forall a\in A\\
 & q_a &\ge& c_l(a), & \forall a\in A\\
 & \rho_{vw}=1 &\Rightarrow &\pi_v\ge\pi_w +1, & \forall (v,w)\in A\\
 & \rho_{vw}=0 &\Rightarrow &\pi_w\ge\pi_v +1,& \forall (v,w)\in A\\
 & \rho_{vw}=1 &\Rightarrow &q((v,w))\ge 0,& \forall (v,w)\in A\\
 & \rho_{vw}=0 &\Rightarrow &q((v,w))\le 0,& \forall (v,w)\in A\\
 & q_a \in \R, & & &\forall a\in A\\
 & \pi_v \in \R, & & & \forall v\in V\\
 & \rho_{vw} \in \{0,1\},&&& \forall a=(v,w)\in A.\\
\end{align*}
Integer node potentials imply the direction of the arc between the incident nodes. These binary direction 
variables again imply the sign of the actual flow on an arc. Indicator constraints are usually implemented via 
Big-M-constraints of the form 
\begin{align*}
 &\pi_v-\pi_w &\ge & N(\rho_{vw}-1)+1,\\
 &\pi_v-\pi_w&\le &N\rho_{vw}-1, \\
 &q((v,w))&\ge& M(\rho_{vw}-1),\\
 &q((v,w))&\le & M\rho_{vw},\\
 &\rho_{vw} \in \{0,1\}.&&\\
\end{align*}
with sufficient big values for $M$ and $N$. This model heavily relies on the Big-M / indicator constraints.
For any MIP solver these indicator or Big-M constraints are difficult to handle, because the optimal vertex of the LP 
polyhedron can be quite far from the optimal mixed integer solution.\\

In the tables below we will refer to this model as \textit{nodepotential}.\\
 
\textbf{Relaxation:} For a mixed 
integer program in practice the runnning time is mainly influenced by the time used in the branch and bound process
of the solver. Throughout this process the solver has always a lower bound and an upper bound for the solution value. 
If we stop this process before the optimal solution is found we can still take the dual bound of the MIP as a (weaker) 
bound for the maximum flow on the specified arc. Thus we can create a heuristic algorithm by limiting the running time 
or the number of nodes in the branch-and-bound process. We use a node limit in order to get reproducable results. \\

We refer to this model solved within a node limit of $X$ nodes as \textit{nodepot\_X}.
 
 
 \subsection{MIP with Binary Direction Variables and Separation of Acyclicity Constraints}
In section \ref{model:AcyclicityConstraints} we described a model using acyclicity constraints on the binary directions 
for each cycle that was found during the solving process.
This model itself is independent of the implementation of the acyclicity constraints. But since a graph can have an 
exponential number of cycles, writing down all constraints of the model alone could take exponential time. The 
model redundancies we described in \ref{prop:redundantAcyclicityCons} are not enough to sufficiently reduce the model 
size - in fact it could happen that the conditions for \ref{prop:redundantAcyclicityCons} do not apply at all in 
certain networks (though we also did not proof that a clever generalization of the proposition couldn't do better). 
For example the condition of the proposition states that there have to be two cycles with exactly one arc in common. 
But there are of course example networks not containing any two cycles like this. (You could just subdivide every arc 
in a network. Then each pair of two cycles has at least two arcs in common.)\\

Because of this the implementation does not add all the acyclicity constraints explicitely. Instead, the MIP Solver 
gets a general constraint that demands that there is no cyclic flow in the network. When this constraint is checked and 
there is cyclic flow somewhere in the network, a new linear acyclicity constraint on the cycle with the detected cyclic 
flow is added. An Acyclicity Constraint Handler was implemented for this in Lamatto \cite{lamatto} with SCIP 
\cite{scip} \cite{Achterberg2009} as solver. \\

Where this model is solved unto optimality we refer to this model in the tables as \textit{sepa\_all}.\\

% Like the other exact model with node potentials this model takes lots of time to compute the optimal solution. In 
% a network there are huge numbers of arcs to be computed that yield similar subproblems, some of them being 
% difficult and running very long. Like in the Node Potential Model we could only produce an exact solution for the 
% "gaslib-40" network while the algorithm was running too long on the other gaslib test instances.

\textbf{Relaxations of the Exact Separation Model: }
If we want to have fast answers or compute bigger networks the exact model with separation of acyclicity 
constraints does not work in practice. Nevertheless this model gives us an interesting relaxation of the acyclic 
flowbound problem for free: 

We can limit the time or the number of nodes in the branch and bound tree in the solver for each arc in the network. 
This is exactly the same approach we also used in the node potential model. If an optimal solution can be found with low 
effort, we get the optimum bound. If the situation is difficult and we run into the limit 
we just take the dual bound of the mixed integer program. This number is always an upper bound because it is always 
greater or equal to the optimum (which is the maximum flow). \\

With this algorithm we will always get some solution. This solution might be $\infty$. To get rid of the infinite 
values, we can combine it with a simple bound estimate. For example we can take the sum of all ingoing flow as upper 
bound for all arcs with a dual bound that is greater than this. Depending on the preset limit this dual solution could
be closer to or further from the optimum. 

This relaxation was implemented with a limit on the nodes branched again and is compared to 
others in the tables below. The tables refer to this relaxation as "sepa\_X" for the exact MIP with separation of 
acyclicity constraints and a node limit of \textit{X} in the branch and bound process of the MIP.\\

% this is roberts code, props to him!
\textbf{Acyclicity Constraints on a Cycle Base: }
This idea was the starting point of this thesis and implemented by Robert Schwarz some time before. It is like the 
relaxation seen before an incomplete application of the acyclicity constraints. It adds all its acyclicity constraints 
in the beginning, but strongly limits the numbder of those constraints. The advantages are easier implementation and 
hope for a faster running time since the solver does not need to add new constraints all the time.

We have seen in \ref{bild:reichtkreisbasis2} that the acyclicity constraints of a small subset of the cycles (like a 
cycle base) do not suffice to forbid cyclic flow  in the network. Still we can try to use them as a relaxation to the 
exact problem. This will already avoid cyclic flow on single cycles that are not touching each other. The tables show 
how the idea works out in practice, we refer to it as \textit{cyclebase}.

\subsection{Cyclic Flow Bounds}%describe the exactfb algo implemented before
\label{model:cyclicFlow}
To start a comparison we need a bound value to which we can compare. This value should be one that is fast and 
easy to compute, in some way sensible and not too far away from a realistic solution, and of course a valid upper 
bound. 
One of the first algorithmic problems that one might think of after seeing the flowbound problem is the normal minimum 
cost flow problem \ref{def:mincostflow}. Setting a negative weight on only one arc in the network will 
maximize flow on this specific arc. We described the connections with this problem in section \ref{sect:mincostflow}. 

We can set the maximal flow capacity on an arc to the natural upper bound "sum of all ingoing flow" if no tighter 
capacity bounds are given. This is a very easy condition derived from the acyclicity and can always be applied.

This model is also implemented in Lamatto. It is modeled as a mixed integer programm with only flow balance and 
capacity constraints. Binary directions are not contained in this model. Because this MIP model also served as the 
basis for the more specific MIP models it is a relaxation of all the others which just add some more constraints or 
variables.

We will refer to this model as "cyclic bounds" respectively "cyclic bounds + flowsum" in the tables below. We compare 
the bounds from the different algorithms to the bounds found with this approach. 


\section{Computational results}
\subsection{Test Instances}

All algorithms where tested with instances of the \textit{"GasLib"} test library \cite{gaslib}. This is a 
collection of gas network and nomination data based on real-world data from the german gas network operator "Open Grid 
Europe GmbH. 

The first network we test the algorithms on is the small GasLib-40 network with just 3 exits, 29 entries, 39 
pipes and 6 compressors. Figure \ref{bild:gaslib40} shows this network which apparently has a relatively small number 
of elements and especially a structure with few cycles.

\begin{figure}[h!, scale = 0.6]
  \centering
  \includegraphics[width=.6\textwidth]{gaslib-40_bild.pdf}
  \caption{schematic plot of the GasLib-40 gasnet with relatively few cycles and elements}
  \label{bild:gaslib40}
\end{figure}


The other network is the GasLib-582 network (see figure \ref{bild:gaslib582} ) containing 31 entries, 129 exits, 422 
inner nodes, 278 pipes, 269 shortpipes and a number of other connection elements. This network is based on distorted 
real-world data in order to yield computationally realistic behavior. In this network not only the number of elements 
but also the number of cycles in the graph is much higher. The expectation is thus a much higher running time and 
difficulty to find good solutions. GasLib contains several distinct nominations for this network. The test were 
carried out on a set of 5 nominations chosen, one for each temperature class. The result tables show that the behavior
of the algorithms is only by a small part affected by the nominations, which yield rather similar overall outcomes.\\

\begin{figure}[h!, scale = 0.6]
  \centering
  \includegraphics[width=.8\textwidth]{gaslib-582_bild.pdf}
  \caption{schematic plot of the GasLib-582 gasnet representing a realistic real-world gasnet}
  \label{bild:gaslib582}
\end{figure}

A detailed description of the GasLib library can be found in 
\cite{HumpolaJoormannOucherifPfetschScheweSchmidtSchwarz:2015}.\\

\subsection{Test Settings}
%TODO muss ich den PC mit Anzahl Kernen etc spezifizieren?!?
The processor of the Computer used for testing was a 64 bit Intel(R) Xeon(R) CPU E3-1290 V2 @ 3.70GHz with 8 cores. The 
PC had a RAM of 16 Gigabytes. The running times might be influenced by the fact that the tests were not running 
exclusively. The MIP model with node potentials was using Gurobi as solver, which parallelized the solving process on 
the 8 cores, other than SCIP. 


\subsection{Bound Improvements}
As first metric to compare the results of the different approaches we will use the actual bound improvements of our 
implementations. This is a very natural way of comparing the results because it was the original question we asked: How 
can we get good bounds for the Acyclic Flowbound Problem? 

As starting point for our comparison we can take the cyclic flowbound approach (see \ref{model:cyclicFlow} ). It turns 
out that it is always a good idea to combine it with the simple upper bound "sum of all ingoing flow": Out of the 39 
pipes in the small GasLib-40 test network there were 48 bound improvements (when both upper and lower bounds were 
improved counting as two improvements) by using the ingoing flow sum as upper bound. In other words there were 48 
bounds where cyclic flowbound approach was worse than the trivial flow sum bound. 
Since it has almost no effect on the running time of the algorithm one should always use this trivial bound. This 
bound was also preset for the computations using other models and improved their performance.\\

The comparison of the cyclic bounds + flowsum approach with the other approaches is the main part here. The complete 
tables can be found in the appendix \ref{appendix:boundimprove}. 

We can look at the GasLib-40 test and recognize that the heuristic algorithm is not better than the cyclic bounds at 
all in this example. All other algorithms found the optimum solution instead, but with very different timings. Though 
using acyclicity constraints only on a cycle base is not optimal in general, in this case it is sufficient and yields 
the best running time among the optimal results. The nodepotential model shows a quite reasonable performance, while 
the full separation needs almost 2 minutes just on this tiny example.

\begin{center}

\begin{tabular}{ l | c | c }
\textbf{gaslib-40} & Time & Improvement\\
\hline
 cyclic bounds+flowsum& $<1$ s& - \\
 cycle base& $1$ s & optimum\\
 heuristic& $<1$ s& none\\
 nodepotential& $4$ s & optimum\\ 
 sepa\_all& $112$ s& optimum\\
\end{tabular} 
\end{center}

The GasLib-135 network was used for a few test computations, but the exact models did not solve and there seemed to be 
no advantage to the realistic network. This is why the comparisons are carried out only on the GasLib-582 testset.

For the bigger instances of the GasLib-582 testset the picture looks much different than on GasLib-40. This is only in 
small parts influenced by the nominations - as the tables in \ref{appendix:boundimprove} show the differences between 
different nominations on the same network is small and the tendency is always the same. The exact algorithms and even 
the approach putting acyclicity constraints only on the cycles of a cycle base fail completely here. Thus we can only 
compare the heuristic bounds and see how fast they are improving. The following table is compiled of the 
rounded geometric mean values of the test runs.

\begin{center}
\begin{tabular}{ l | c | c | c | c }
\textbf{gaslib-582 geom. mean} & Time  & Fixed Flows & Bounds tightened & avg improvement \\
\hline
 cyclic bounds+flowsum& $1$ s& 365 & - & -\\
 heuristic& $ 11$ s& 365& 164 & 4885 \\
 nodepot\_60000& $19$ min/8 cores & 368 &58  &  3004 \\ 
 nodepot\_500000& $130$ min/8 cores & 368 &70  & 2896 \\ 
 sepa\_1000& $ 50$ min & 378 & 98 & 3869 \\
 sepa\_5000& $ 151$ min & 378 & 209 & 4037 \\
 sepa\_20000& $ 354$ min & 378 & 241 & 4060 \\
 sepa\_60000& $ 651$ min  & 378& 280& 4015\\
\end{tabular} 
\end{center}

The table shows that the heuristic does substantially better than the cyclic bounds approach. It also needs a quite 
short time and where it improves bounds it has a high average improvement. The nodepotential approach is the looser 
here: despite higher nodelimits than the separation approach its results are even worse than the results found 
by the heuristic. Thus in practice the heuristic and where the time is less important the separation approach seem to 
fit best. 

While running time of the separation algorithms increases underproportional with the nodelimit, the quality of the 
solution improves quite well in the beginning. Even the average improvement, which is not changing much with higher 
node limits, is better than for the node potential approach. Note that this is in contrast to the behavior of 
the two exact models in the small GasLib-40 network where the node potential model was far superior over the separation 
of acyclicity constraints. It is possible that for solving the model completely still node potential could be a better 
model.


\subsection{Model building impact}
The bounds computed can be read in by Lamatto and used by the solver to improve building of other models like the 
discretization. The impact of the computed flow bounds on this model is a measure of the actual benefits acyclic 
flow bounds could have on the solving process. The tables in \ref{appendix:modelbuild} show how model sizes change when 
reading in bounds from the different models.


\begin{center}
\begin{tabular}{ l | c | c | c }
\textbf{gaslib-40} & Fixed Directions & Variables&Constraints\\
\hline
 cyclic bounds&24 &1477&2009 \\
 cyclic bounds+flowsum &24 & 1477 &2009 \\
 nodepotential& 25 &955 &1473  \\ 
 sepa& 34 &955 &1473 \\
\end{tabular} 
\end{center}
If we compare the results on this small gaslib-40 network with its table of bound values there are two interesting 
points. In building the model there is no difference between the cyclic bounds that were computed with respect to the 
sum of ingoing flow and the ones were the sum of ingoing flow was not set as upper flow bound. Obviously these bounds 
are already used implicitely. Nevertheless it is worth using these natural bounds already in the bound computation, 
since all the algorithms run much faster and give better results when they are given these bounds before. 

The second point is that the number of fixed flow directions differs a lot from the nodepotential to the separation 
model, although the exact algorithms both found the same optimal solution. The reason is a single numerical difference. 
It might be useful to round values which are extremely close to zero (like in this case $1^{-10}$) to get more 
fixations for the model.\\

As we could expect the optimal solutions yield smaller models both in the number of variables and the number of 
constraints. 

As example we take the results of gaslib-582 with the nomination warm\_1111 to see how the model changes with better 
bounds. The behavior is similar for the other nominations, for more tables see \ref{appendix:modelbuild}.
\begin{center}
\begin{tabular}{ l | c | c | c | c | c }

\textbf{gaslib-582 warm\_1111} & Fixed Directions &Variables &Constraints\\
\hline
 cyclic bounds+flowsum& 458 & 5673 &8183 \\
 heuristic& 458& 5589 &8097\\
 sepa\_1000& 487 & 4865 & 7335 \\
 sepa\_5000& 492& 4745 & 7212  \\
 sepa\_20000& 494 & 4433& 6886 \\
 sepa\_60000& 496 & 4371 & 6823 \\
\end{tabular} 
\end{center}

The table show that the number of fixed direction is increasing only little when better bounds are available, but the 
number of Variables might decrease by more than 20\% and the number of constraints by more than 16\% , even if the 
bounds are still far from optimal. This example has the highest improvements, but also the other ones show a 
significant decline of used variables and constraint by more than 10\%.\\


For the big networks we are only able to compare the results of heuristics because the exact algorithms take far 
too long for solving. Among them the original heuristic approach is the onyl one that really can be called fast. But if 
there is enough time the exact models with node limits do find better bounds. The tables show that improved bounds 
yield a smaller model. The more nodes we allow in the 
separation process, the tighter the bounds. With tighter bounds we get a smaller model. Because of the smaller model 
sizes it could in fact make sense to compute such bounds to accelerate the solving process in the end. 
